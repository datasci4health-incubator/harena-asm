{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import sys, traceback\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL='bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model_path):\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_path,do_lower_case=False)\n",
    "    model = BertModel.from_pretrained(model_path, output_hidden_states = True)\n",
    "    model.eval()\n",
    "    return model,tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states(model,tokenizer,marked_text):\n",
    "    \n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    \n",
    "    # Display the words with their indeces.\n",
    "    for tup in zip(tokenized_text, indexed_tokens):\n",
    "        print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
    "        \n",
    "    # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    # Run the text through BERT, and collect all of the hidden states produced\n",
    "    # from all 12 layers. \n",
    "    with torch.no_grad():\n",
    "\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        hidden_states = outputs[2]\n",
    "        \n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_plot(hidden_states):\n",
    "    print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "    layer_i = 0\n",
    "\n",
    "    print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "    batch_i = 0\n",
    "\n",
    "    print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "    token_i = 0\n",
    "\n",
    "    print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))\n",
    "    \n",
    "    # For the 5th token in our sentence, select its feature values from layer 5.\n",
    "    token_i = 1\n",
    "    layer_i = 1\n",
    "    vec = hidden_states[layer_i][batch_i][token_i]\n",
    "\n",
    "    # Plot the values as a histogram to show their distribution.\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.hist(vec, bins=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_four_layers(token_embeddings):\n",
    "    # Stores the token vectors, with shape [22 x 3,072]\n",
    "    token_vecs_cat = []\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "    \n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Concatenate the vectors (that is, append them together) from the last \n",
    "        # four layers.\n",
    "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "        # Use `cat_vec` to represent `token`.\n",
    "        token_vecs_cat.append(cat_vec)\n",
    "\n",
    "    print ('token_vecs_cat Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_four_layers(token_embeddings):\n",
    "    # Stores the token vectors, with shape [22 x 768]\n",
    "    token_vecs_sum = []\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Sum the vectors from the last four layers.\n",
    "        sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    \n",
    "        # Use `sum_vec` to represent `token`.\n",
    "        token_vecs_sum.append(sum_vec)\n",
    "\n",
    "    print ('token_vecs_sum Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))\n",
    "    \n",
    "    return token_vecs_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_twelve_layers(hidden_states):\n",
    "    # `hidden_states` has shape [13 x 1 x 22 x 768]\n",
    "\n",
    "    # `token_vecs` is a tensor with shape [22 x 768]\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "\n",
    "    # Calculate the average of all 22 token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    \n",
    "    print ('token_vecs Shape is: %d x %d' % (len(token_vecs), len(token_vecs[0])))\n",
    "    \n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_given_token(text, token_vecs_sum, i):\n",
    "    print('First 5 vector values for each instance of', text)\n",
    "    print('')\n",
    "    print(text, str(token_vecs_sum[i][:5]))\n",
    "#     print(\"bank robber  \", str(token_vecs_sum[i][:5]))\n",
    "#     print(\"river bank   \", str(token_vecs_sum[i][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def calculate_cosine_distance(token_vecs_sum_1, token_vecs_sum_2):\n",
    "#     print('-------------')\n",
    "    \n",
    "#     print(str(token_vecs_sum_1), str(token_vecs_sum_2))\n",
    "    \n",
    "    # Calculate the cosine similarity between the word bank \n",
    "    # in \"bank robber\" vs \"river bank\" (different meanings).\n",
    "    diff_bank = 1 - cosine(token_vecs_sum_1, token_vecs_sum_2)\n",
    "\n",
    "    # Calculate the cosine similarity between the word bank\n",
    "    # in \"bank robber\" vs \"bank vault\" (same meaning).\n",
    "#     same_bank = 1 - cosine(token_vecs_sum_1, token_vecs_sum_1)\n",
    "\n",
    "#     print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
    "    print('Vector similarity:  %.2f' % diff_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'init_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b737e3ab956c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBERT_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mhidden_states_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hidden_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarked_text_compound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# hidden_states_2 = get_hidden_states(model, tokenizer, marked_text2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'init_model' is not defined"
     ]
    }
   ],
   "source": [
    "text1 = \"man\" \n",
    "text2 =   \"woman\"\n",
    "\n",
    "marked_text_compound = \"[CLS] \" + text1 + \" [SEP]\" + text2 + \" [SEP]\"\n",
    "marked_text1 = \"[CLS] \" + text1 + \" [SEP]\"\n",
    "marked_text2 = \"[CLS] \" + text2 + \" [SEP]\"\n",
    "\n",
    "\n",
    "model,tokenizer = init_model(BERT_MODEL)\n",
    "hidden_states_1 = get_hidden_states(model, tokenizer, marked_text_compound)\n",
    "# hidden_states_2 = get_hidden_states(model, tokenizer, marked_text2)\n",
    "\n",
    "#     print_and_plot(hidden_states)\n",
    "        \n",
    "# `hidden_states` is a Python list.\n",
    "print('      Type of hidden_states: ', type(hidden_states))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', hidden_states[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_vecs_sum Shape is: 5 x 768\n",
      "token_vecs Shape is: 5 x 768\n",
      "Vector similarity:  0.94\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings_1 = torch.stack(hidden_states_1, dim=0)\n",
    "# token_embeddings_2 = torch.stack(hidden_states_2, dim=0)\n",
    "\n",
    "# print(token_embeddings_1.size())\n",
    "\n",
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings_1 = torch.squeeze(token_embeddings_1, dim=1)\n",
    "# token_embeddings_2 = torch.squeeze(token_embeddings_2, dim=1)\n",
    "\n",
    "# print(token_embeddings_1.size())\n",
    "\n",
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings_1 = token_embeddings_1.permute(1,0,2)\n",
    "# token_embeddings_2 = token_embeddings_2.permute(1,0,2)\n",
    "\n",
    "# print(token_embeddings_1.size())\n",
    "\n",
    "# token_vecs_sum_1 = concatenate_four_layers(token_embeddings_1)\n",
    "# token_vecs_sum_2 = concatenate_four_layers(token_embeddings_2)\n",
    "\n",
    "token_vecs_sum_1 = sum_four_layers(token_embeddings_1)\n",
    "# token_vecs_sum_2 = sum_four_layers(token_embeddings_2)\n",
    "\n",
    "sentence_embedding_1 = avg_twelve_layers(hidden_states_1)\n",
    "# sentence_embedding_2 = avg_twelve_layers(hidden_states_2)\n",
    "\n",
    "# print (\"Our final sentence embedding vector of shape:\", sentence_embedding_1.size())\n",
    "# print(token_vecs_sum_1[1])\n",
    "\n",
    "# get_embeddings_given_token('bacteria: ', token_vecs_sum_1, 1)\n",
    "# get_embeddings_given_token('hand: ', token_vecs_sum_2, 1)\n",
    "\n",
    "\n",
    "calculate_cosine_distance(token_vecs_sum_1[1], token_vecs_sum_1[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "md = torch.load('./pytorch_model.bin', map_location='cpu')\n",
    "for k in md:\n",
    "    if (k == 'bert.embeddins.word_embeddings.weight'):\n",
    "        embeds = md[k]\n",
    "    \n",
    "    for l in range(len(embeds)):\n",
    "        vector = embeds[1]\n",
    "    for m in range(len(vector)):\n",
    "            print(round(vector[m].tolist(), 6, end=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello sir\")).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids)\n",
    "last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.get_input_embeddings()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.LongTensor([28995])\n",
    "embeddings(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying ontology alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xmltodict\n",
    "\n",
    "import xmltodict\n",
    "\n",
    "with open('../documents/ontologies/desc2020.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
