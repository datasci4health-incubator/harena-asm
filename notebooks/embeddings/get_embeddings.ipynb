{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 841 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.4)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "  Downloading sentencepiece-0.1.94-cp37-cp37m-manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2020.10.28-cp37-cp37m-manylinux2010_x86_64.whl (666 kB)\n",
      "\u001b[K     |████████████████████████████████| 666 kB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from transformers) (3.11.4)\n",
      "Collecting tokenizers==0.9.2\n",
      "  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 7.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 9.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.50.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf->transformers) (49.6.0.post20201009)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.17.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=7cb106125d0f3a3566fc1a723adf53e26e240989c7326884309b663618d860c4\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: filelock, sentencepiece, regex, tokenizers, sacremoses, transformers\n",
      "Successfully installed filelock-3.0.12 regex-2020.10.28 sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "BERT_MODEL='bert-base-cased'\n",
    "# BERT_MODEL='dmis-lab/biobert-base-cased-v1.1'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=False)\n",
    "model = BertModel.from_pretrained(BERT_MODEL, output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states(model,tokenizer,marked_text):\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    \n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs[2]\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    \n",
    "    hidden_states = get_hidden_states(model, tokenizer, marked_text)\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "    \n",
    "    return token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = \"A 58-year-old African-American woman presents to the ER with episodic pressing/burning anterior chest pain that began two days earlier for the first time in her life. The pain started while she was walking, radiates to the back, and is accompanied by nausea, diaphoresis and mild dyspnea, but is not increased on inspiration. The latest episode of pain ended half an hour prior to her arrival. She is known to have hypertension and obesity. She denies smoking, diabetes, hypercholesterolemia, or a family history of heart disease. She currently takes no medications. Physical examination is normal. The EKG shows nonspecific changes.\"\n",
    "tokenized_input = tokenizer.tokenize(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_embeddings = []\n",
    "last_embeddings = []\n",
    "\n",
    "with open(\"embeddings/label.tsv\", \"w\") as labels_file:\n",
    "    for token in tokenized_input:\n",
    "        if (not token.startswith(\"##\")):\n",
    "            marked_text = \"[CLS] \" + token + \" [SEP]\"\n",
    "\n",
    "            print(token, file=labels_file)\n",
    "\n",
    "            token_embeddings = get_embeddings(marked_text)\n",
    "        \n",
    "            first_embedding_layer = token_embeddings[1][1]\n",
    "            last_embedding_layer = token_embeddings[1][12]\n",
    "\n",
    "            tsv_rows = ''\n",
    "            for e in last_embedding_layer:\n",
    "                tsv_rows += str(e.item()) + '\\t'\n",
    "            last_embeddings.append(tsv_rows)\n",
    "            \n",
    "            tsv_rows = ''\n",
    "            for e in first_embedding_layer:\n",
    "                tsv_rows += str(e.item()) + '\\t'\n",
    "            first_embeddings.append(tsv_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bert/first_embedding.tsv\", \"w\") as f:\n",
    "    for e in first_embeddings:\n",
    "        print (e, file=f)\n",
    "        \n",
    "with open(\"bert/last_embedding.tsv\", \"w\") as f:\n",
    "    for e in last_embeddings:\n",
    "        print (e, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
