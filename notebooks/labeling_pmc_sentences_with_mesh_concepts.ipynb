{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysolr in /opt/conda/lib/python3.7/site-packages (3.9.0)\n",
      "Requirement already satisfied: requests>=2.9.1 in /opt/conda/lib/python3.7/site-packages (from pysolr) (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.9.1->pysolr) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.9.1->pysolr) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.9.1->pysolr) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.9.1->pysolr) (1.25.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pysolr\n",
    "pip install spacy==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /opt/conda/lib/python3.7/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /opt/conda/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.6)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3.post20200325)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.45.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.4)\n",
      "Requirement already satisfied: thinc==7.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pysolr, os\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokenizer = nlp.Defaults.create_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"responseHeader\":{\\n    \"zkConnected\":null,\\n    \"status\":0,\\n    \"QTime\":326,\\n    \"params\":{\\n      \"q\":\"{!lucene}*:*\",\\n      \"distrib\":\"false\",\\n      \"df\":\"_text_\",\\n      \"rows\":\"10\",\\n      \"echoParams\":\"all\"}},\\n  \"status\":\"OK\"}\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PMC_URL = 'http://' + os.environ['SOLR_HOST'] + ':8983/solr/pmc'\n",
    "MESH_URL = 'http://' + os.environ['SOLR_HOST'] + ':8983/solr/mesh3'\n",
    "\n",
    "pmc_solr = pysolr.Solr(PMC_URL, always_commit=False)\n",
    "mesh_solr = pysolr.Solr(MESH_URL, always_commit=False)\n",
    "\n",
    "# Do a health check.\n",
    "mesh_solr.ping()\n",
    "pmc_solr.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = nlp.tokenizer.explain(text)\n",
    "\n",
    "    return [t[1] for t in tokens if t[0] == 'TOKEN']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_grams(doc):\n",
    "    i = 0\n",
    "    n_grams = []\n",
    "    for i in range(i, len(doc)):\n",
    "        n_gram = []\n",
    "        n_gram.append(doc[i])\n",
    "\n",
    "        if (i<len(doc)-1):\n",
    "            n_gram.append(doc[i+1])\n",
    "        if (i<len(doc)-2):\n",
    "            n_gram.append(doc[i+2])    \n",
    "\n",
    "        n_grams.append(n_gram)\n",
    "    return n_grams\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(n_gram):\n",
    "    separator = ' '\n",
    "    text_value = separator.join(n_gram)\n",
    "    query = '{}:\\\"{}\\\"'.format('ConceptName', text_value)\n",
    "#     print(query)\n",
    "    try:\n",
    "        results = mesh_solr.search(query)\n",
    "\n",
    "        if (len(results) != 0):\n",
    "            for r in results:\n",
    "                return (r['ConceptName'], len(n_gram))\n",
    "        elif len(n_gram)-1>0: \n",
    "            return search(n_gram[:len(n_gram)-1])\n",
    "        else: return ('', len(n_gram)-1)\n",
    "    except: return ('', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(n_grams):\n",
    "    n = 0\n",
    "    word_index = 0\n",
    "    labels = ['O' for i in range(len(n_grams))]\n",
    "    for n_gram in n_grams:\n",
    "        if n > 1:\n",
    "            word_index = word_index + 1\n",
    "            n= n-1\n",
    "            continue\n",
    "\n",
    "        concept, n = search(n_gram)\n",
    "        if (concept):\n",
    "            for i in range(n):\n",
    "                labels[word_index+i] = concept\n",
    "\n",
    "        word_index = word_index + 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_uni_class(n_grams):\n",
    "    n = 0\n",
    "    word_index = 0\n",
    "    labels = ['O' for i in range(len(n_grams))]\n",
    "    for n_gram in n_grams:\n",
    "        if n > 1:\n",
    "            word_index = word_index + 1\n",
    "            n= n-1\n",
    "            continue\n",
    "\n",
    "        concept, n = search(n_gram)\n",
    "        if (concept):\n",
    "            for i in range(n):\n",
    "                labels[word_index+i] = 'B-MESH' if i == 0 else 'I-MESH'\n",
    "\n",
    "        word_index = word_index + 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple sentence example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', '58-year', 'old', 'African', 'American', 'woman', 'presents', 'to', 'the', 'ER', 'with', 'episodic', 'pressing', 'burning', 'anterior', 'chest', 'pain', 'that', 'began', 'two', 'days', 'earlier', 'for', 'the', 'first', 'time', 'in', 'her', 'life', 'The', 'pain', 'started', 'while', 'she', 'was', 'walking', 'radiates', 'to', 'the', 'back', 'and', 'is', 'accompanied', 'by', 'nausea', 'diaphoresis', 'and', 'mild', 'dyspnea', 'but', 'is', 'not', 'increased', 'on', 'inspiration', 'The', 'latest', 'episode', 'of', 'pain', 'ended', 'half', 'an', 'hour', 'prior', 'to', 'her', 'arrival', 'She', 'is', 'known', 'to', 'have', 'hypertension', 'and', 'obesity', 'She', 'denies', 'smoking', 'diabetes', 'hypercholesterolemia', 'or', 'a', 'family', 'history', 'of', 'heart', 'disease', 'She', 'currently', 'takes', 'no', 'medications', 'Physical', 'examination', 'is', 'normal', 'The', 'EKG', 'shows', 'nonspecific', 'changes', 'The', 'urogenital', 'system', 'failled']\n"
     ]
    }
   ],
   "source": [
    "original_sentence = \"A 58-year-old African-American woman presents to the ER with episodic pressing/burning anterior chest pain that began two days earlier for the first time in her life. The pain started while she was walking, radiates to the back, and is accompanied by nausea, diaphoresis and mild dyspnea, but is not increased on inspiration. The latest episode of pain ended half an hour prior to her arrival. She is known to have hypertension and obesity. She denies smoking, diabetes, hypercholesterolemia, or a family history of heart disease. She currently takes no medications. Physical examination is normal. The EKG shows nonspecific changes. The urogenital system failled.\"\n",
    "tokens = tokenize(original_sentence)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O A\n",
      "O 58-year\n",
      "O old\n",
      "O African\n",
      "O American\n",
      "O woman\n",
      "O presents\n",
      "O to\n",
      "O the\n",
      "O ER\n",
      "O with\n",
      "O episodic\n",
      "O pressing\n",
      "O burning\n",
      "O anterior\n",
      "O chest\n",
      "O pain\n",
      "O that\n",
      "O began\n",
      "O two\n",
      "O days\n",
      "O earlier\n",
      "O for\n",
      "O the\n",
      "O first\n",
      "O time\n",
      "O in\n",
      "O her\n",
      "B-MESH life\n",
      "O The\n",
      "O pain\n",
      "O started\n",
      "O while\n",
      "O she\n",
      "O was\n",
      "O walking\n",
      "O radiates\n",
      "O to\n",
      "O the\n",
      "B-MESH back\n",
      "O and\n",
      "O is\n",
      "O accompanied\n",
      "O by\n",
      "B-MESH nausea\n",
      "O diaphoresis\n",
      "O and\n",
      "O mild\n",
      "B-MESH dyspnea\n",
      "O but\n",
      "O is\n",
      "O not\n",
      "O increased\n",
      "O on\n",
      "O inspiration\n",
      "O The\n",
      "O latest\n",
      "O episode\n",
      "O of\n",
      "O pain\n",
      "O ended\n",
      "O half\n",
      "O an\n",
      "O hour\n",
      "O prior\n",
      "O to\n",
      "O her\n",
      "O arrival\n",
      "O She\n",
      "O is\n",
      "O known\n",
      "O to\n",
      "O have\n",
      "B-MESH hypertension\n",
      "O and\n",
      "B-MESH obesity\n",
      "O She\n",
      "O denies\n",
      "O smoking\n",
      "O diabetes\n",
      "B-MESH hypercholesterolemia\n",
      "O or\n",
      "O a\n",
      "O family\n",
      "O history\n",
      "O of\n",
      "B-MESH heart\n",
      "B-MESH disease\n",
      "O She\n",
      "O currently\n",
      "O takes\n",
      "O no\n",
      "O medications\n",
      "O Physical\n",
      "O examination\n",
      "O is\n",
      "O normal\n",
      "O The\n",
      "O EKG\n",
      "O shows\n",
      "O nonspecific\n",
      "O changes\n",
      "O The\n",
      "B-MESH urogenital\n",
      "I-MESH system\n",
      "O failled\n"
     ]
    }
   ],
   "source": [
    "n_grams = get_n_grams(tokens)\n",
    "labels = get_labels_uni_class(n_grams)\n",
    "for label, token in zip(labels, tokens):\n",
    "    print(label, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = get_n_grams(tokens)\n",
    "labels = get_labels(n_grams)\n",
    "for label, token in zip(labels, tokens):\n",
    "    print(label, token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentences from PMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "i=0\n",
    "nrows = 1000\n",
    "numFound=0\n",
    "while i*nrows <= 2000:\n",
    "    results = pmc_solr.search('*:*', rows=1000, start=i*nrows)\n",
    "    \n",
    "#     print(results.raw_response['response'])\n",
    "#     numFound = results.raw_response['response']['numFound']\n",
    "    i = i+1\n",
    "    \n",
    "    for result in results:\n",
    "        sentence = ''\n",
    "        if 'abstract' in result:\n",
    "            for abstract in result['abstract']:\n",
    "                sentence = sentence + abstract + ' '\n",
    "            sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "dicts= []\n",
    "for sentence in sentences:\n",
    "    words = tokenize(sentence)\n",
    "    n_grams =  get_n_grams(words)\n",
    "    tags = get_labels_uni_class(n_grams)\n",
    "    each_sentence = []\n",
    "    for word,tag in zip(words, tags):\n",
    "        dicts.append({ 'sentence_idx':i, 'word': word, 'tag':tag})\n",
    "#     dicts.append(each_sentence)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dicts)\n",
    "\n",
    "df.to_csv('mesh.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
